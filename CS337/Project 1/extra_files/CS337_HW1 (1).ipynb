{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9hibjA5HpMNF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from imdb import IMDb\n",
    "from nltk import pos_tag\n",
    "import rapidfuzz\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yR7cfMF3vrTj",
    "outputId": "5adf28c9-51d7-4223-b698-9cdf22e39475"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\25851\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ytoRPQ_2wdhc"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6oG2GWRyPIH",
    "outputId": "0935dcb2-425e-4b63-da76-90c272e21969"
   },
   "outputs": [],
   "source": [
    "links = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "hashtag = re.compile(r'#[\\s]+\\w+')\n",
    "tag = re.compile(r'@[^:]+:')\n",
    "punc = re.compile(r'[^\\w\\d\\s]+')\n",
    "\n",
    "stop_words = {'.org', 'aahh', 'aarrgghh', 'abt', 'ftl', 'ftw', 'fu', 'fuck', 'fucks', 'gtfo', 'gtg', 'haa',\n",
    "                          'hah', 'hahah', 'haha', 'hahaha', 'hahahaha', 'hehe', 'heh', 'hehehe', 'hi', 'hihi', 'hihihi',\n",
    "                          'http', 'https', 'huge', 'huh', 'huhu', 'huhuhu', 'idk', 'iirc', 'im', 'imho', 'imo', 'ini',\n",
    "                          'irl', 'ish', 'isn', 'isnt', 'j/k', 'jk', 'jus', 'just', 'justwit', 'juz', 'kinda', 'kthx',\n",
    "                          'kthxbai', 'kyou', 'laa', 'laaa', 'lah', 'lanuch', 'leavg', 'leh', 'lol', 'lols', 'ltd',\n",
    "                          'mph', 'mrt', 'msg', 'msgs', 'muahahahahaha', 'nb', 'neways', 'ni', 'nice', 'pls', 'plz',\n",
    "                          'plzz', 'psd', 'pte', 'pwm', 'pwned', 'qfmft', 'qft', 'tis', 'tm', 'tmr', 'tyty', 'tyvm',\n",
    "                          'um', 'umm', 'viv', 'vn', 'vote', 'voted', 'w00t', 'wa', 'wadever', 'wah', 'wasn', 'wasnt',\n",
    "                          'wassup', 'wat', 'watcha', 'wateva', 'watever', 'watnot', 'wats', 'wayy', 'wb', 'weren',\n",
    "                          'werent', 'whaha', 'wham', 'whammy', 'whaow', 'whatcha', 'whatev', 'whateva', 'whatevar',\n",
    "                          'whatever', 'whatnot', 'whats', 'whatsoever', 'whatz', 'whee', 'whenz', 'whey', 'whore',\n",
    "                          'whores', 'whoring', 'wo', 'woah', 'woh', 'wooohooo', 'woot', 'wow', 'wrt', 'wtb', 'wtf',\n",
    "                          'wth', 'wts', 'wtt', 'www', 'xs', 'ya', 'yaah', 'yah', 'yahh', 'yahoocurrency', 'yall', 'yar',\n",
    "                          'yay', 'yea', 'yeah', 'yeahh', 'yeh', 'yhoo', 'ymmv', 'young', 'youre', 'yr', 'yum', 'yummy',\n",
    "                          'yumyum', 'yw', 'zomg', 'zz', 'zzz', 'loz', 'lor', 'loh', 'tsk', 'meh', 'lmao', 'wanna',\n",
    "                          'doesn', 'liao', 'didn', 'didnt', 'omg', 'ohh', 'ohgod', 'hoh', 'hoo', 'bye', 'byee', 'byeee',\n",
    "                          'byeeee', 'lmaolmao', 'yeahhh', 'yeahhhh', 'yeahhhhh', 'yup', 'yupp', 'hahahahahahaha',\n",
    "                          'hahahahahah', 'hahhaha', 'wooohoooo', 'wahaha', 'haah', '2moro', 'veh', 'noo', 'nooo',\n",
    "                          'noooo', 'hahas', 'ooooo', 'ahahaha', 'ahahahahah', 'tomolow', 'accent', 'accented',\n",
    "                          'accents', 'acne', 'ads', 'afaik', 'aft', 'ago', 'ahead', 'ain', 'aint', 'aircon', 'alot',\n",
    "                          'am', 'annoy', 'annoyed', 'annoys', 'anycase', 'anymore', 'app', 'apparently', 'apps', 'argh',\n",
    "                          'ass', 'asses', 'awesome', 'babeh', 'bad', 'bai', 'based', 'bcos', 'bcoz', 'bday', 'bit',\n",
    "                          'biz', 'blah', 'bleh', 'bless', 'blessed', 'blk', 'blogcatalog', 'bro', 'bros', 'btw', 'byee',\n",
    "                          'com', 'congrats', 'contd', 'conv', 'cos', 'cost', 'costs', 'couldn', 'couldnt', 'cove',\n",
    "                          'coves', 'coz', 'crap', 'cum', 'curnews', 'curr', 'cuz', 'dat', 'de', 'diff', 'dis', 'doc',\n",
    "                          'doesn', 'doesnt', 'don', 'AAWWW', 'dont', 'dr', 'dreamt', 'drs', 'due', 'dun', 'dunno',\n",
    "                          'duper', 'eh', 'ehh', 'emo', 'emos', 'eng', 'esp', 'fadein', 'ffs', 'fml', 'frm', 'fwah',\n",
    "                          'g2g', 'gajshost', 'gd', 'geez', 'gg', 'gigs', 'gtfo.1', 'gtg.1', 'hasn', 'hasnt', 'hav',\n",
    "                          'haven', 'havent', 'hee', 'hello', 'hey', 'hmm', 'ho', 'hohoho', 'lotsa', 'lotta', 'luv',\n",
    "                          'ly', 'macdailynews', 'nite', 'nom', 'noscript', 'nvr', 'nw', 'ohayo', 'omfg', 'omfgwtf',\n",
    "                          'omgwtfbbq', 'omw', 'org', 'pf', 'pic', 'pm', 'pmsing', 'ppl', 'pre', 'pro', 'rawr', 'rawrr',\n",
    "                          'rofl', 'roflmao', 'rss', 'rt', 'sec', 'secs', 'seem', 'seemed', 'seems', 'sgreinfo', 'shd',\n",
    "                          'shit', 'shits', 'shitz', 'shld', 'shouldn', 'shouldnt', 'shudder', 'sq', 'sqft', 'sqm',\n",
    "                          'srsly', 'stfu', 'stks', 'su', 'suck', 'sucked', 'sucks', 'suckz', 'sux', 'swf', 'tart',\n",
    "                          'tat', 'tgif', 'thanky', 'thk', 'thks', 'tht', 'tired', 'hahahahahahahahaha', 'hahahahaha',\n",
    "                          'hahahahah', 'zzzzz', 'hahahahha', 'lolololol', 'lololol', 'lolol', 'lol', 'dude', 'hmmm',\n",
    "                          'humm', 'tumblr', 'kkkk', 'fk', 'yayyyyyy', 'fffffffuuuuuuuuuuuu', 'zzzz', 'noooooooooo',\n",
    "                          'hahahhaha', 'woohoo', 'lalalalalalala', 'lala', 'lalala', 'lalalala', 'whahahaahahahahahah',\n",
    "                          'hahahahahahahahahahaha', 'ahhh', 'RT', 'rt', 'gif', 'amp', '.com', '.ly', '.net',\n",
    "                          \"\"\"'\"\"\", ',', '.', ';'}\n",
    "# stop_words.update(addition_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tV4I-YbxpoLI"
   },
   "outputs": [],
   "source": [
    "# Reading JSON data from a file\n",
    "input_file = 'gg2013.json'\n",
    "output_file = 'gg2013.csv'\n",
    "\n",
    "# Converting JSON data to a pandas DataFrame\n",
    "df = pd.read_json(input_file)\n",
    "\n",
    "# # Writing DataFrame to a CSV file\n",
    "# df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-ezDieyhy1bb"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Tokenize the text\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_words = []\n",
    "    for w in word_tokens:\n",
    "        if w == '&':\n",
    "            filtered_words.append('and')\n",
    "        elif w.lower() == 'tv':\n",
    "            filtered_words.append('telvision')\n",
    "        elif w.lower() == 'mini-series' or w.lower() == 'miniseries':\n",
    "            filtered_words.append('mini series')\n",
    "        else:\n",
    "            if w.lower() not in stop_words:\n",
    "                filtered_words.append(w)\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the 'remove_stopwords' function to the 'text' column\n",
    "df['text'] = df['text'].apply(remove_stopwords)\n",
    "\n",
    "# Save the DataFrame back to a CSV file\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K8pgv3D90K3f"
   },
   "outputs": [],
   "source": [
    "def tweet_preprocess(tweet):\n",
    "    tweet = emoji.replace_emoji(tweet, replace='')\n",
    "    tweet = re.sub(hashtag, '', tweet)\n",
    "    tweet = re.sub(tag, '', tweet)\n",
    "    tweet = re.sub(links, '', tweet)\n",
    "    tweet = re.sub(punc, ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yOoiczsUQmH1"
   },
   "outputs": [],
   "source": [
    "OFFICIAL_AWARDS = ['cecil b. demille award', 'best motion picture - drama',\n",
    "                        'best performance by an actress in a motion picture - drama',\n",
    "                        'best performance by an actor in a motion picture - drama',\n",
    "                        'best motion picture - comedy or musical',\n",
    "                        'best performance by an actress in a motion picture - comedy or musical',\n",
    "                        'best performance by an actor in a motion picture - comedy or musical',\n",
    "                        'best animated feature film', 'best foreign language film',\n",
    "                        'best performance by an actress in a supporting role in a motion picture',\n",
    "                        'best performance by an actor in a supporting role in a motion picture',\n",
    "                        'best director - motion picture', 'best screenplay - motion picture',\n",
    "                        'best original score - motion picture', 'best original song - motion picture',\n",
    "                        'best television series - drama',\n",
    "                        'best performance by an actress in a television series - drama',\n",
    "                        'best performance by an actor in a television series - drama',\n",
    "                        'best television series - comedy or musical',\n",
    "                        'best performance by an actress in a television series - comedy or musical',\n",
    "                        'best performance by an actor in a television series - comedy or musical',\n",
    "                        'best mini series or motion picture made for television',\n",
    "                        'best performance by an actress in a mini series or motion picture made for television',\n",
    "                        'best performance by an actor in a mini series or motion picture made for television',\n",
    "                        'best performance by an actress in a supporting role in a series mini series or motion picture made for television',\n",
    "                        'best performance by an actor in a supporting role in a series mini series or motion picture made for television']\n",
    "\n",
    "TITLE = r\"(?:[A-Z][a-z]*\\.\\s*)?\"\n",
    "NAME1 = r\"[A-Z][a-z]+,?\\s+\"\n",
    "MIDDLE_I = r\"(?:[A-Z][a-z]*\\.?\\s*)?\"\n",
    "NAME2 = r\"[A-Z][a-z]+\"\n",
    "\n",
    "WHITE_SPACE = r'\\s+'\n",
    "SINGLE_CHAR = r'(?<!\\S)\\S(?!\\S)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['text'].apply(tweet_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          JLo  s dress    \n",
       "1         What  s making Sofia Vergara  s boobs stay lik...\n",
       "2          Kerry Washington is EVERYTHING Dying over her...\n",
       "3                          Anne Hathaway has got me living \n",
       "4                Jennifer Lopez  s lace dress   Thoughts   \n",
       "                                ...                        \n",
       "174638     I was sad that Mandy Patinkin did n t win  he...\n",
       "174639     Jennifer Lawrence aceptando premio      t co ...\n",
       "174640    Golden Globes lots of fashion messes   but gla...\n",
       "174641    Did they have mug shots at the golden globes  ...\n",
       "174642    Says    I also did n t get the Acting Nominati...\n",
       "Name: processed, Length: 174643, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altAwardName(OFFICIAL_AWARDS, extra_award, extra_name):\n",
    "  flag = 0\n",
    "\n",
    "  for official in OFFICIAL_AWARDS:\n",
    "    for award in extra_award[official]:\n",
    "      if \"score\" in award:\n",
    "        extra = \"score\"\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "      if \"song\" in award:\n",
    "        extra = \"song\"\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "      if \"television\" in award:\n",
    "        extra = award.replace(\"television\", 'tv')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"television\", 't.v.')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"motion picture\" in award:\n",
    "        extra = award.replace(\"motion picture\", \"movie\")\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"motion picture\", \"film\")\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"film\" in award:\n",
    "        extra = award.replace(\"film\", \"motion picture\")\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"film\", \"movie\")\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"comedy or musical\" in award:\n",
    "        extra = award.replace(\"comedy or musical\", 'comedy')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"comedy or musical\", 'musical')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"made for television\" in award:\n",
    "        extra = award.replace(\"made for television\", 'television')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"made for television\", 'tv')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"made for television\", 't.v.')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"series, mini-series or motion picture made for television\" in award:\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'series')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'mini-series')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'miniseries')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\", 'tv')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'television')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'tv movie')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'tv series')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"series, mini-series or motion picture made for television\",\n",
    "            'television series')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"mini-series or motion picture made for television\" in award:\n",
    "        extra = award.replace(\n",
    "            \"mini-series or motion picture made for television\", 'miniseries')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"mini-series or motion picture made for television\", 'mini-series')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"mini-series or motion picture made for television\", 'tv movie')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\n",
    "            \"mini-series or motion picture made for television\",\n",
    "            'television movie')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"television series\" in award:\n",
    "        extra = award.replace(\"television series\", 'series')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"television series\", 'tv')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"television series\", 't.v.')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "        extra = award.replace(\"television series\", 'television')\n",
    "        if extra not in extra_award[official]:\n",
    "          flag = 1\n",
    "          extra_award[official].append(extra)\n",
    "          extra_name[official].append(\n",
    "              [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"television series - comedy or musical\" in award:\n",
    "\n",
    "        for word in [\n",
    "            \"tv comedy\", \"tv musical\", \"comedy series\", \"t.v. comedy\",\n",
    "            \"t.v. musical\", \"television comedy\", \"television musical\"\n",
    "        ]:\n",
    "          extra = award.replace(\"television series - comedy or musical\", word)\n",
    "          if extra not in extra_award[official]:\n",
    "            flag = 1\n",
    "            extra_award[official].append(extra)\n",
    "            extra_name[official].append(\n",
    "                [item for item in extra.split() if not item in TO_DELETE])\n",
    "\n",
    "      if \"television series - drama\" in award:\n",
    "        for word in [\n",
    "            \"tv drama\", \"drama series\", \"television drama\", \"t.v. drama\"\n",
    "        ]:\n",
    "          extra = award.replace(\"television series - drama\", word)\n",
    "          if extra not in extra_award[official]:\n",
    "            flag = 1\n",
    "            extra_award[official].append(extra)\n",
    "            extra_name[official].append(\n",
    "                [item for item in extra.split() if not item in TO_DELETE])\n",
    "  if flag == 1:\n",
    "    altAwardName(OFFICIAL_AWARDS, extra_award, extra_name)\n",
    "\n",
    "def getTweetByAward(OFFICIAL_AWARDS, extra_name, tweets):\n",
    "    tweet_by_award_dict = dict()\n",
    "    for award in OFFICIAL_AWARDS:\n",
    "        tweet_by_award_dict[award] = []\n",
    "    \n",
    "    OFFICIAL_AWARDS.sort(key=lambda s: len(s), reverse=True)\n",
    "    for award in OFFICIAL_AWARDS:\n",
    "        tweet_length = len(tweets)\n",
    "        for i in range(tweet_length - 1, -1, -1):\n",
    "            tweet = tweets[i]\n",
    "            for extra in extra_name[award]:\n",
    "                if 'actor' in tweet.lower() or 'actress' in tweet.lower():\n",
    "                    if 'actor' in award or 'actress' in award:\n",
    "                        if 'actor' in extra or 'actress' in extra:\n",
    "                            if 'supporting' in tweet.lower():\n",
    "                                if 'supporting' in award:\n",
    "                                    if 'supporting' in extra:\n",
    "                                        flag = True\n",
    "                                        for word in extra:\n",
    "                                            if flag == True:\n",
    "                                                flag = flag and word.lower() in tweet.lower()\n",
    "    \n",
    "                                        if flag == True:\n",
    "                                            tweet_by_award_dict[award].append(tweet)\n",
    "                                            break\n",
    "                            else:\n",
    "                                flag = True\n",
    "                                for word in extra:\n",
    "                                    if flag == True:\n",
    "                                        flag = flag and word.lower() in tweet.lower()\n",
    "    \n",
    "                                if flag == True:\n",
    "                                    tweet_by_award_dict[award].append(tweet)\n",
    "                                    break\n",
    "                else:\n",
    "                    flag = True\n",
    "                    for word in extra:\n",
    "                        if flag == True:\n",
    "                            flag = flag and word.lower() in tweet.lower()\n",
    "    \n",
    "                    if flag == True:\n",
    "                        tweet_by_award_dict[award].append(tweet)\n",
    "                        break\n",
    "    return tweet_by_award_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df.processed.to_list()\n",
    "extra_award = dict()\n",
    "fresh_names = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_var import *\n",
    "\n",
    "for award in OFFICIAL_AWARDS:\n",
    "    fresh_names[award] = [[item for item in award.split() if not item in TO_DELETE]]\n",
    "    extra_award[award] = []\n",
    "    extra_award[award].append(award)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "altAwardName(OFFICIAL_AWARDS, extra_award, fresh_names)\n",
    "    \n",
    "tweet_by_award_dict = getTweetByAward(OFFICIAL_AWARDS, fresh_names, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tweet_by_award_dict.items():\n",
    "    value = list(set(value))\n",
    "    for i in range(len(value)):\n",
    "        value[i] = re.sub(WHITE_SPACE, ' ', value[i])\n",
    "        value[i] = re.sub(SINGLE_CHAR, ' ', value[i])\n",
    "    value = list(set(value))\n",
    "    tweet_by_award_dict[key] = value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cecil b. demille award': [['cecil', 'b.', 'demille']],\n",
       " 'best motion picture - drama': [['motion', 'picture', 'drama'],\n",
       "  ['movie', 'drama'],\n",
       "  ['film', 'drama']],\n",
       " 'best performance by an actress in a motion picture - drama': [['actress',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'drama'],\n",
       "  ['actress', 'movie', 'drama'],\n",
       "  ['actress', 'film', 'drama']],\n",
       " 'best performance by an actor in a motion picture - drama': [['actor',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'drama'],\n",
       "  ['actor', 'movie', 'drama'],\n",
       "  ['actor', 'film', 'drama']],\n",
       " 'best motion picture - comedy or musical': [['motion',\n",
       "   'picture',\n",
       "   'comedy',\n",
       "   'musical'],\n",
       "  ['movie', 'comedy', 'musical'],\n",
       "  ['film', 'comedy', 'musical'],\n",
       "  ['motion', 'picture', 'comedy'],\n",
       "  ['motion', 'picture', 'musical'],\n",
       "  ['movie', 'comedy'],\n",
       "  ['movie', 'musical'],\n",
       "  ['film', 'comedy'],\n",
       "  ['film', 'musical']],\n",
       " 'best performance by an actress in a motion picture - comedy or musical': [['actress',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'comedy',\n",
       "   'musical'],\n",
       "  ['actress', 'movie', 'comedy', 'musical'],\n",
       "  ['actress', 'film', 'comedy', 'musical'],\n",
       "  ['actress', 'motion', 'picture', 'comedy'],\n",
       "  ['actress', 'motion', 'picture', 'musical'],\n",
       "  ['actress', 'movie', 'comedy'],\n",
       "  ['actress', 'movie', 'musical'],\n",
       "  ['actress', 'film', 'comedy'],\n",
       "  ['actress', 'film', 'musical']],\n",
       " 'best performance by an actor in a motion picture - comedy or musical': [['actor',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'comedy',\n",
       "   'musical'],\n",
       "  ['actor', 'movie', 'comedy', 'musical'],\n",
       "  ['actor', 'film', 'comedy', 'musical'],\n",
       "  ['actor', 'motion', 'picture', 'comedy'],\n",
       "  ['actor', 'motion', 'picture', 'musical'],\n",
       "  ['actor', 'movie', 'comedy'],\n",
       "  ['actor', 'movie', 'musical'],\n",
       "  ['actor', 'film', 'comedy'],\n",
       "  ['actor', 'film', 'musical']],\n",
       " 'best animated feature film': [['animated', 'film'],\n",
       "  ['animated', 'motion', 'picture'],\n",
       "  ['animated', 'movie']],\n",
       " 'best foreign language film': [['foreign', 'film'],\n",
       "  ['foreign', 'motion', 'picture'],\n",
       "  ['foreign', 'movie']],\n",
       " 'best performance by an actress in a supporting role in a motion picture': [['actress',\n",
       "   'supporting',\n",
       "   'motion',\n",
       "   'picture'],\n",
       "  ['actress', 'supporting', 'movie'],\n",
       "  ['actress', 'supporting', 'film']],\n",
       " 'best performance by an actor in a supporting role in a motion picture': [['actor',\n",
       "   'supporting',\n",
       "   'motion',\n",
       "   'picture'],\n",
       "  ['actor', 'supporting', 'movie'],\n",
       "  ['actor', 'supporting', 'film']],\n",
       " 'best director - motion picture': [['director', 'motion', 'picture'],\n",
       "  ['director', 'movie'],\n",
       "  ['director', 'film']],\n",
       " 'best screenplay - motion picture': [['screenplay', 'motion', 'picture'],\n",
       "  ['screenplay', 'movie'],\n",
       "  ['screenplay', 'film']],\n",
       " 'best original score - motion picture': [['original',\n",
       "   'score',\n",
       "   'motion',\n",
       "   'picture'],\n",
       "  ['score'],\n",
       "  ['original', 'score', 'movie'],\n",
       "  ['original', 'score', 'film']],\n",
       " 'best original song - motion picture': [['original',\n",
       "   'song',\n",
       "   'motion',\n",
       "   'picture'],\n",
       "  ['song'],\n",
       "  ['original', 'song', 'movie'],\n",
       "  ['original', 'song', 'film']],\n",
       " 'best television series - drama': [['television', 'series', 'drama'],\n",
       "  ['tv', 'series', 'drama'],\n",
       "  ['t.v.', 'series', 'drama'],\n",
       "  ['series', 'drama'],\n",
       "  ['tv', 'drama'],\n",
       "  ['t.v.', 'drama'],\n",
       "  ['television', 'drama'],\n",
       "  ['tv', 'drama'],\n",
       "  ['drama', 'series'],\n",
       "  ['television', 'drama'],\n",
       "  ['t.v.', 'drama']],\n",
       " 'best performance by an actress in a television series - drama': [['actress',\n",
       "   'television',\n",
       "   'series',\n",
       "   'drama'],\n",
       "  ['actress', 'tv', 'series', 'drama'],\n",
       "  ['actress', 't.v.', 'series', 'drama'],\n",
       "  ['actress', 'series', 'drama'],\n",
       "  ['actress', 'tv', 'drama'],\n",
       "  ['actress', 't.v.', 'drama'],\n",
       "  ['actress', 'television', 'drama'],\n",
       "  ['actress', 'tv', 'drama'],\n",
       "  ['actress', 'drama', 'series'],\n",
       "  ['actress', 'television', 'drama'],\n",
       "  ['actress', 't.v.', 'drama']],\n",
       " 'best performance by an actor in a television series - drama': [['actor',\n",
       "   'television',\n",
       "   'series',\n",
       "   'drama'],\n",
       "  ['actor', 'tv', 'series', 'drama'],\n",
       "  ['actor', 't.v.', 'series', 'drama'],\n",
       "  ['actor', 'series', 'drama'],\n",
       "  ['actor', 'tv', 'drama'],\n",
       "  ['actor', 't.v.', 'drama'],\n",
       "  ['actor', 'television', 'drama'],\n",
       "  ['actor', 'tv', 'drama'],\n",
       "  ['actor', 'drama', 'series'],\n",
       "  ['actor', 'television', 'drama'],\n",
       "  ['actor', 't.v.', 'drama']],\n",
       " 'best television series - comedy or musical': [['television',\n",
       "   'series',\n",
       "   'comedy',\n",
       "   'musical'],\n",
       "  ['tv', 'series', 'comedy', 'musical'],\n",
       "  ['t.v.', 'series', 'comedy', 'musical'],\n",
       "  ['television', 'series', 'comedy'],\n",
       "  ['television', 'series', 'musical'],\n",
       "  ['series', 'comedy', 'musical'],\n",
       "  ['tv', 'comedy', 'musical'],\n",
       "  ['t.v.', 'comedy', 'musical'],\n",
       "  ['television', 'comedy', 'musical'],\n",
       "  ['tv', 'comedy'],\n",
       "  ['tv', 'musical'],\n",
       "  ['comedy', 'series'],\n",
       "  ['t.v.', 'comedy'],\n",
       "  ['t.v.', 'musical'],\n",
       "  ['television', 'comedy'],\n",
       "  ['television', 'musical'],\n",
       "  ['tv', 'series', 'comedy'],\n",
       "  ['tv', 'series', 'musical'],\n",
       "  ['t.v.', 'series', 'comedy'],\n",
       "  ['t.v.', 'series', 'musical'],\n",
       "  ['series', 'comedy'],\n",
       "  ['tv', 'comedy'],\n",
       "  ['t.v.', 'comedy'],\n",
       "  ['television', 'comedy'],\n",
       "  ['series', 'musical'],\n",
       "  ['tv', 'musical'],\n",
       "  ['t.v.', 'musical'],\n",
       "  ['television', 'musical']],\n",
       " 'best performance by an actress in a television series - comedy or musical': [['actress',\n",
       "   'television',\n",
       "   'series',\n",
       "   'comedy',\n",
       "   'musical'],\n",
       "  ['actress', 'tv', 'series', 'comedy', 'musical'],\n",
       "  ['actress', 't.v.', 'series', 'comedy', 'musical'],\n",
       "  ['actress', 'television', 'series', 'comedy'],\n",
       "  ['actress', 'television', 'series', 'musical'],\n",
       "  ['actress', 'series', 'comedy', 'musical'],\n",
       "  ['actress', 'tv', 'comedy', 'musical'],\n",
       "  ['actress', 't.v.', 'comedy', 'musical'],\n",
       "  ['actress', 'television', 'comedy', 'musical'],\n",
       "  ['actress', 'tv', 'comedy'],\n",
       "  ['actress', 'tv', 'musical'],\n",
       "  ['actress', 'comedy', 'series'],\n",
       "  ['actress', 't.v.', 'comedy'],\n",
       "  ['actress', 't.v.', 'musical'],\n",
       "  ['actress', 'television', 'comedy'],\n",
       "  ['actress', 'television', 'musical'],\n",
       "  ['actress', 'tv', 'series', 'comedy'],\n",
       "  ['actress', 'tv', 'series', 'musical'],\n",
       "  ['actress', 't.v.', 'series', 'comedy'],\n",
       "  ['actress', 't.v.', 'series', 'musical'],\n",
       "  ['actress', 'series', 'comedy'],\n",
       "  ['actress', 'tv', 'comedy'],\n",
       "  ['actress', 't.v.', 'comedy'],\n",
       "  ['actress', 'television', 'comedy'],\n",
       "  ['actress', 'series', 'musical'],\n",
       "  ['actress', 'tv', 'musical'],\n",
       "  ['actress', 't.v.', 'musical'],\n",
       "  ['actress', 'television', 'musical']],\n",
       " 'best performance by an actor in a television series - comedy or musical': [['actor',\n",
       "   'television',\n",
       "   'series',\n",
       "   'comedy',\n",
       "   'musical'],\n",
       "  ['actor', 'tv', 'series', 'comedy', 'musical'],\n",
       "  ['actor', 't.v.', 'series', 'comedy', 'musical'],\n",
       "  ['actor', 'television', 'series', 'comedy'],\n",
       "  ['actor', 'television', 'series', 'musical'],\n",
       "  ['actor', 'series', 'comedy', 'musical'],\n",
       "  ['actor', 'tv', 'comedy', 'musical'],\n",
       "  ['actor', 't.v.', 'comedy', 'musical'],\n",
       "  ['actor', 'television', 'comedy', 'musical'],\n",
       "  ['actor', 'tv', 'comedy'],\n",
       "  ['actor', 'tv', 'musical'],\n",
       "  ['actor', 'comedy', 'series'],\n",
       "  ['actor', 't.v.', 'comedy'],\n",
       "  ['actor', 't.v.', 'musical'],\n",
       "  ['actor', 'television', 'comedy'],\n",
       "  ['actor', 'television', 'musical'],\n",
       "  ['actor', 'tv', 'series', 'comedy'],\n",
       "  ['actor', 'tv', 'series', 'musical'],\n",
       "  ['actor', 't.v.', 'series', 'comedy'],\n",
       "  ['actor', 't.v.', 'series', 'musical'],\n",
       "  ['actor', 'series', 'comedy'],\n",
       "  ['actor', 'tv', 'comedy'],\n",
       "  ['actor', 't.v.', 'comedy'],\n",
       "  ['actor', 'television', 'comedy'],\n",
       "  ['actor', 'series', 'musical'],\n",
       "  ['actor', 'tv', 'musical'],\n",
       "  ['actor', 't.v.', 'musical'],\n",
       "  ['actor', 'television', 'musical']],\n",
       " 'best mini-series or motion picture made for television': [['mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['mini-series', 'motion', 'picture', 't.v.'],\n",
       "  ['mini-series', 'movie', 'television'],\n",
       "  ['mini-series', 'film', 'television'],\n",
       "  ['mini-series', 'motion', 'picture', 'television'],\n",
       "  ['mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['mini-series', 'motion', 'picture', 't.v.'],\n",
       "  ['miniseries'],\n",
       "  ['mini-series'],\n",
       "  ['tv', 'movie'],\n",
       "  ['television', 'movie'],\n",
       "  ['mini-series', 'movie', 'tv'],\n",
       "  ['mini-series', 'film', 'tv'],\n",
       "  ['mini-series', 'movie', 't.v.'],\n",
       "  ['mini-series', 'film', 't.v.'],\n",
       "  ['mini-series', 'movie', 'television'],\n",
       "  ['mini-series', 'movie', 'tv'],\n",
       "  ['mini-series', 'movie', 't.v.'],\n",
       "  ['mini-series', 'film', 'television'],\n",
       "  ['mini-series', 'film', 'tv'],\n",
       "  ['mini-series', 'film', 't.v.'],\n",
       "  ['t.v.', 'movie']],\n",
       " 'best performance by an actress in a mini-series or motion picture made for television': [['actress',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['actress', 'mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['actress', 'mini-series', 'motion', 'picture', 't.v.'],\n",
       "  ['actress', 'mini-series', 'movie', 'television'],\n",
       "  ['actress', 'mini-series', 'film', 'television'],\n",
       "  ['actress', 'mini-series', 'motion', 'picture', 'television'],\n",
       "  ['actress', 'mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['actress', 'mini-series', 'motion', 'picture', 't.v.'],\n",
       "  ['actress', 'miniseries'],\n",
       "  ['actress', 'mini-series'],\n",
       "  ['actress', 'tv', 'movie'],\n",
       "  ['actress', 'television', 'movie'],\n",
       "  ['actress', 'mini-series', 'movie', 'tv'],\n",
       "  ['actress', 'mini-series', 'film', 'tv'],\n",
       "  ['actress', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actress', 'mini-series', 'film', 't.v.'],\n",
       "  ['actress', 'mini-series', 'movie', 'television'],\n",
       "  ['actress', 'mini-series', 'movie', 'tv'],\n",
       "  ['actress', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actress', 'mini-series', 'film', 'television'],\n",
       "  ['actress', 'mini-series', 'film', 'tv'],\n",
       "  ['actress', 'mini-series', 'film', 't.v.'],\n",
       "  ['actress', 't.v.', 'movie']],\n",
       " 'best performance by an actor in a mini-series or motion picture made for television': [['actor',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['actor', 'mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['actor', 'mini-series', 'motion', 'picture', 't.v.'],\n",
       "  ['actor', 'mini-series', 'movie', 'television'],\n",
       "  ['actor', 'mini-series', 'film', 'television'],\n",
       "  ['actor', 'mini-series', 'motion', 'picture', 'television'],\n",
       "  ['actor', 'mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['actor', 'mini-series', 'motion', 'picture', 't.v.'],\n",
       "  ['actor', 'miniseries'],\n",
       "  ['actor', 'mini-series'],\n",
       "  ['actor', 'tv', 'movie'],\n",
       "  ['actor', 'television', 'movie'],\n",
       "  ['actor', 'mini-series', 'movie', 'tv'],\n",
       "  ['actor', 'mini-series', 'film', 'tv'],\n",
       "  ['actor', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actor', 'mini-series', 'film', 't.v.'],\n",
       "  ['actor', 'mini-series', 'movie', 'television'],\n",
       "  ['actor', 'mini-series', 'movie', 'tv'],\n",
       "  ['actor', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actor', 'mini-series', 'film', 'television'],\n",
       "  ['actor', 'mini-series', 'film', 'tv'],\n",
       "  ['actor', 'mini-series', 'film', 't.v.'],\n",
       "  ['actor', 't.v.', 'movie']],\n",
       " 'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television': [['actress',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['actress',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'tv'],\n",
       "  ['actress',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   't.v.'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'movie', 'television'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'film', 'television'],\n",
       "  ['actress',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['actress',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'tv'],\n",
       "  ['actress',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   't.v.'],\n",
       "  ['actress', 'supporting', 'series'],\n",
       "  ['actress', 'supporting', 'mini-series'],\n",
       "  ['actress', 'supporting', 'miniseries'],\n",
       "  ['actress', 'supporting', 'tv'],\n",
       "  ['actress', 'supporting', 'television'],\n",
       "  ['actress', 'supporting', 'tv', 'movie'],\n",
       "  ['actress', 'supporting', 'tv', 'series'],\n",
       "  ['actress', 'supporting', 'television', 'series'],\n",
       "  ['actress', 'supporting', 'series,', 'miniseries'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series'],\n",
       "  ['actress', 'supporting', 'series,', 'tv', 'movie'],\n",
       "  ['actress', 'supporting', 'series,', 'television', 'movie'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'movie', 'tv'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'film', 'tv'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'film', 't.v.'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'movie', 'television'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'movie', 'tv'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'film', 'television'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'film', 'tv'],\n",
       "  ['actress', 'supporting', 'series,', 'mini-series', 'film', 't.v.'],\n",
       "  ['actress', 'supporting', 't.v.'],\n",
       "  ['actress', 'supporting', 't.v.', 'series'],\n",
       "  ['actress', 'supporting', 'series,', 't.v.', 'movie']],\n",
       " 'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television': [['actor',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['actor',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   't.v.'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'movie', 'television'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'film', 'television'],\n",
       "  ['actor',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   'television'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'motion', 'picture', 'tv'],\n",
       "  ['actor',\n",
       "   'supporting',\n",
       "   'series,',\n",
       "   'mini-series',\n",
       "   'motion',\n",
       "   'picture',\n",
       "   't.v.'],\n",
       "  ['actor', 'supporting', 'series'],\n",
       "  ['actor', 'supporting', 'mini-series'],\n",
       "  ['actor', 'supporting', 'miniseries'],\n",
       "  ['actor', 'supporting', 'tv'],\n",
       "  ['actor', 'supporting', 'television'],\n",
       "  ['actor', 'supporting', 'tv', 'movie'],\n",
       "  ['actor', 'supporting', 'tv', 'series'],\n",
       "  ['actor', 'supporting', 'television', 'series'],\n",
       "  ['actor', 'supporting', 'series,', 'miniseries'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series'],\n",
       "  ['actor', 'supporting', 'series,', 'tv', 'movie'],\n",
       "  ['actor', 'supporting', 'series,', 'television', 'movie'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'movie', 'tv'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'film', 'tv'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'film', 't.v.'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'movie', 'television'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'movie', 'tv'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'movie', 't.v.'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'film', 'television'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'film', 'tv'],\n",
       "  ['actor', 'supporting', 'series,', 'mini-series', 'film', 't.v.'],\n",
       "  ['actor', 'supporting', 't.v.'],\n",
       "  ['actor', 'supporting', 't.v.', 'series'],\n",
       "  ['actor', 'supporting', 'series,', 't.v.', 'movie']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aFGa57mvIz2A"
   },
   "outputs": [],
   "source": [
    "nominees = {}\n",
    "nominee_names = {}\n",
    "award_names_extracted = {}\n",
    "award_stoplist = ['best','award','for','or','made', 'the', 'in', 'a', 'by', 'performance', 'an','golden','globes','role', '-', 'of', 'go', \n",
    "                  'b.', 'game', 'yes', 'should', 'could', 'would', 'have', 'been', 'i', 'this', 'that', 'even', 'with', 'I']\n",
    "name_pattern = re.compile(r'[A-Z][a-z]+\\s[A-Z][a-z]+')\n",
    "person_award = ['actor', 'actress', 'director', 'demille']\n",
    "tv_related_award = ['tv', 't.v.', 'TV', 'television', 'film', 'motion', 'picture', 'series', 'animated', 'animation']\n",
    "nomination_words = [\"nominated\", \"nominee\", \"nominate\", \"ceremony\", \"category\", \"announced\", \"congratulations\", \"congrats\", \"honored\", \n",
    "                    \"prestigious\", \"deserving\", \"celebrate\", \"recognized\", \"for\", \"deserves\", \"recognize\", \"believe\", \"overlook\", \"deserved\", \"up\", \"rooting\", \"hope\", \"hoping\",\n",
    "                   \"finally\", \"happy for\", \"robbed\", \"overrated\", \"pick\", \"tough\", \"competition\",\"earned\", \"well\", \"favorite\", \"clear\", \"clearly\", \"well-deserved\", \"right\", \"direction\"]\n",
    "verbs = ['was', 'were', 'is', 'are']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in tweet_by_award_dict.items():\n",
    "    i = len(value) - 1\n",
    "    while i >= 0:\n",
    "        if any(nom_word in value[i] for nom_word in nomination_words):\n",
    "            words = value[i].split()\n",
    "            value[i] = ' '.join(['' if word.lower() in award_stoplist else word for word in words])\n",
    "        else:\n",
    "            value.pop(i)\n",
    "        i -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aFGa57mvIz2A"
   },
   "outputs": [],
   "source": [
    "for award in OFFICIAL_AWARDS:\n",
    "    nominees[award]=[]\n",
    "    nominee_names[award]=[]\n",
    "    #award_names_extracted[award] = [a for a in award.split() if a not in award_stoplist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(quote, language='english'):\n",
    "    tokens = word_tokenize(quote)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tree = nltk.ne_chunk(tags)\n",
    "    names=[]\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'PERSON':\n",
    "            leave = \" \".join(l[0] for l in subtree.leaves())\n",
    "            names.append(leave)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "aFGa57mvIz2A"
   },
   "outputs": [],
   "source": [
    "# # This dictionary maps each award with lists of tweets that are relevant to the award\n",
    "# map_award_tweet = {}\n",
    "# for award in OFFICIAL_AWARDS:\n",
    "#     map_award_tweet[award] = []\n",
    "#     for tweet in df['processed']:\n",
    "#         count = 0\n",
    "#         for word in award_names_extracted[award]:\n",
    "#             if word in tweet and any(nom_word in tweet for nom_word in nomination_words):\n",
    "#                 tweet = tweet.split()\n",
    "#                 tweet = ' '.join(['' if word.lower() in award_stoplist else word for word in tweet])\n",
    "#                 map_award_tweet[award].append(tweet)\n",
    "#                 count += 1\n",
    "#             if count == 2:\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eGA9H4bdkB84"
   },
   "outputs": [],
   "source": [
    "# for key, value in tweet_by_award_dict.items():\n",
    "#     if any([kw in key for kw in person_award]):\n",
    "#         for tweet in value:\n",
    "#             names = re.findall(name_pattern, tweet)\n",
    "#             for name in names:\n",
    "#                 flag = True\n",
    "#                 for w in tweet_by_award_dict[key]:\n",
    "#                     flag = flag and w not in name.lower().split()\n",
    "#                 if flag:\n",
    "#                     nominee_names[key].append(name)\n",
    "#     else:\n",
    "#         for tweet in value:\n",
    "#             if any([kw in tweet for kw in tv_related_award]):\n",
    "#                 if tweet not in nominee_names[key]:\n",
    "#                     nominee_names[key].append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ben Affleck\n",
      "Argo Ben\n",
      "Argo Excellent\n",
      "Lincoln But\n",
      "Oh Argo\n",
      "President Clinton\n",
      "Ben Afleck\n",
      "Ben Affleck\n",
      "Affleck Mr Affleck Director\n",
      "Argo Ben\n",
      "Director Love\n",
      "No Aaron Paul Peter\n",
      "John Goodman\n",
      "Werner Herzog Christoph Waltz\n",
      "Lincoln Silver Linings Playbooks\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(names)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# for name in names:\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m movies \u001b[38;5;241m=\u001b[39m \u001b[43mia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_movie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(movies) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m movies:\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;66;03m#print(m)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\site-packages\\imdb\\__init__.py:450\u001b[0m, in \u001b[0;36mIMDbBase.search_movie\u001b[1;34m(self, title, results, _episodes)\u001b[0m\n\u001b[0;32m    448\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _episodes:\n\u001b[1;32m--> 450\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_movie\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_episode(title, results)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\site-packages\\imdb\\parser\\http\\__init__.py:421\u001b[0m, in \u001b[0;36mIMDbHTTPAccessSystem._search_movie\u001b[1;34m(self, title, results)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_search_movie\u001b[39m(\u001b[38;5;28mself\u001b[39m, title, results):\n\u001b[1;32m--> 421\u001b[0m     cont \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_search_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmProxy\u001b[38;5;241m.\u001b[39msearch_movie_parser\u001b[38;5;241m.\u001b[39mparse(cont, results\u001b[38;5;241m=\u001b[39mresults)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\site-packages\\imdb\\parser\\http\\__init__.py:409\u001b[0m, in \u001b[0;36mIMDbHTTPAccessSystem._get_search_content\u001b[1;34m(self, kind, ton, results)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mep\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    408\u001b[0m     params \u001b[38;5;241m=\u001b[39m params\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms=ep&\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms=tt&ttype=ep&\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 409\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfind\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;66;03m# print 'URL:', imdbURL_find % params\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cont\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour search returned more than\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m    412\u001b[0m         cont\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplayed the exact matches\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\site-packages\\imdb\\parser\\http\\__init__.py:392\u001b[0m, in \u001b[0;36mIMDbHTTPAccessSystem._retrieve\u001b[1;34m(self, url, size, _noCookies)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m\"\"\"Retrieve the given URL.\"\"\"\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_http_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetching url \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (size: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, url, size)\n\u001b[1;32m--> 392\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlOpener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve_unicode\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PY2 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    394\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\site-packages\\imdb\\parser\\http\\__init__.py:233\u001b[0m, in \u001b[0;36mIMDbURLopener.retrieve_unicode\u001b[1;34m(self, url, size)\u001b[0m\n\u001b[0;32m    231\u001b[0m uopener \u001b[38;5;241m=\u001b[39m build_opener(\u001b[38;5;241m*\u001b[39mhandlers)\n\u001b[0;32m    232\u001b[0m uopener\u001b[38;5;241m.\u001b[39maddheaders \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddheaders)\n\u001b[1;32m--> 233\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43muopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    234\u001b[0m content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_url \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39murl\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\urllib\\request.py:517\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    514\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[0;32m    516\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 517\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[0;32m    520\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\urllib\\request.py:534\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    533\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 534\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m    535\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\urllib\\request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\urllib\\request.py:1389\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\urllib\\request.py:1350\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m-> 1350\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1352\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\csci349\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# nominee = {}\n",
    "# ia = IMDb()\n",
    "# for key, value in tweet_by_award_dict.items():\n",
    "#     nominee[key] = {}\n",
    "#     if any([kw in key for kw in person_award]):\n",
    "#         for tweet in value:\n",
    "#             tweet = tweet.split()\n",
    "#             print(key)\n",
    "#             tweet = [word for word in tweet if word.lower() not in person_award and word.lower() not in nomination_words]\n",
    "#             tweet = ' '.join(tweet)\n",
    "#             print(tweet)\n",
    "#             if any([kw in tweet for kw in person_award]):\n",
    "#                 person_list = ia.search_person(tweet)\n",
    "#                 # Use bigram to extract name\n",
    "#                 for p in person_list:\n",
    "#                     if p[0]['name'] not in nominee[key]:\n",
    "#                         nominee[key][p[0]['name']] = 1\n",
    "#                     else:\n",
    "#                         nominee[key][p[0]]['name'] += 1\n",
    "#             else:\n",
    "#                 #extracted_name = extract_from_tweet(tweet)\n",
    "#                 #print(extracted_name)\n",
    "#                 #if len(extracted_name) != 0:\n",
    "#                 #print(key)\n",
    "#                 movies = ia.search_movie(tweet)\n",
    "#                 movies = [movie for movie in movies if 'year' in movie.keys() and movie['year'] <= 2013]\n",
    "#                 for i in range(len(movies)):\n",
    "#                     if movies[i]['title'] not in nominee:\n",
    "#                         nominee[key][movies[i]['title']] = 1\n",
    "#                     else:\n",
    "#                         nominee[key][movies[i]['title']] += 1\n",
    "\n",
    "nominee = {}\n",
    "ia = IMDb()\n",
    "for key, value in tweet_by_award_dict.items():\n",
    "    nominee[key] = {}\n",
    "    if any([kw in key for kw in person_award]):\n",
    "        for tweet in value:\n",
    "            if any([kw in tweet for kw in person_award]):   \n",
    "                #print(tweet)\n",
    "                tweet = tweet.split()\n",
    "                tweet = [word for word in tweet if word.lower() not in person_award and word.lower() not in nomination_words]\n",
    "                tweet = ' '.join(tweet)\n",
    "                #print(key)\n",
    "                #print(tweet)\n",
    "                names = re.findall(name_pattern, tweet)\n",
    "                #print(names)\n",
    "                for name in names:\n",
    "                    if name not in nominee[key]:\n",
    "                        nominee[key][name] = 1\n",
    "                    else:\n",
    "                        nominee[key][name] += 1\n",
    "    else:\n",
    "        winner = [\"musical\",\"comedy\",\"motion\", \"picture\",\"golden\",\"globe\",\"movie\",\"television\",\"best\",\"or\",\"tv\",\"original\",\"series\",\"animated\",\n",
    "                  \"feature\",\"film\",\"song\",\"drama\",\"-\",\"rt\",\"to\",\"goes\",\"foreign\",'the']\n",
    "        for tweet in value:\n",
    "            if not any([kw in tweet for kw in person_award]):\n",
    "                tweet = tweet.split()\n",
    "                tweet = [word for word in tweet if word.lower() not in winner and word.lower() not in nomination_words]\n",
    "                tweet = ' '.join(tweet)\n",
    "                names = re.findall(name_pattern, tweet)\n",
    "                names = ' '.join(names)\n",
    "                if names != '':\n",
    "                    print(names)\n",
    "                    # for name in names:\n",
    "                    movies = ia.search_movie(names)\n",
    "                    if len(movies) != 0:\n",
    "                        for m in movies:\n",
    "                            #print(m)\n",
    "                            if \"year\" in m:\n",
    "                                if m[\"year\"] == 2013 or m[\"year\"] == 2012 or m[\"year\"] == 2011:\n",
    "                                    if m[\"title\"] not in nominee[key]:\n",
    "                                        nominee[key][m[\"title\"]] = 1\n",
    "                                    else:\n",
    "                                        nominee[key][m[\"title\"]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in nominee.items():\n",
    "    value_2 = nltk.FreqDist(value).most_common(5)\n",
    "    nominee[key] = [n[0] for n in value_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def extract_noun_from_tweet(tweet):\n",
    "#     # Tokenize and tag the tweet\n",
    "#     tokens = word_tokenize(tweet)\n",
    "#     tagged_tokens = pos_tag(tokens)\n",
    "    \n",
    "#     extracted_nouns = []\n",
    "    \n",
    "#     for i, (word, tag) in enumerate(tagged_tokens):\n",
    "#         # If the word is one of the verbs and the next word is in nominated words, \n",
    "#         # extract the noun before the verb\n",
    "#         if word in verbs and i < len(tagged_tokens) - 1 and tagged_tokens[i + 1][0] in nomination_words:\n",
    "#             if i > 0 and 'NN' in tagged_tokens[i - 1][1]:  # Check if it's a noun\n",
    "#                 extracted_nouns.append(tagged_tokens[i - 1][0])\n",
    "        \n",
    "#         # If the word is in nominated words and there's no verb before it,\n",
    "#         # extract the noun after it\n",
    "#         elif word in nomination_words and (i == 0 or tagged_tokens[i - 1][0] not in verbs):\n",
    "#             if i < len(tagged_tokens) - 1 and 'NN' in tagged_tokens[i + 1][1]:  # Check if it's a noun\n",
    "#                 extracted_nouns.append(tagged_tokens[i + 1][0])\n",
    "\n",
    "#     return extracted_nouns\n",
    "def extract_from_tweet(tweet):\n",
    "    # Tokenize and tag the tweet\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "    for i, word in enumerate(tokens):\n",
    "        # If the word is one of the verbs and the next word is in nominated words, \n",
    "        # extract everything before the verb\n",
    "        if word in verbs and i < len(tokens) - 1 and tokens[i + 1] in nomination_words:\n",
    "            return ' '.join(tokens[:i])\n",
    "        \n",
    "        # If the word is in nominated words and there's no verb before it,\n",
    "        # extract everything after it\n",
    "        elif word in nomination_words and (i == 0 or tokens[i - 1] not in verbs):\n",
    "            return ' '.join(tokens[i+1:])\n",
    "\n",
    "    return []  # Return None if no matching pattern is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nameparser import HumanName\n",
    "from nltk import bigrams\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {}\n",
    "ia = IMDb()\n",
    "for key, value in nominee_names.items():\n",
    "    if key not in test:\n",
    "        test[key] = {}\n",
    "    for tweet in value:\n",
    "        if any([kw in key for kw in person_award]):\n",
    "            bigrams = nltk.bigrams(tweet.split())\n",
    "            # use bigram list to extract name\n",
    "            \n",
    "            \n",
    "            # names = extract_name(tweet)\n",
    "            # for name in names:\n",
    "            #     if name not in test[key]:\n",
    "            #         test[key][name] = 1\n",
    "            #     else:\n",
    "            #         test[key][name] += 1\n",
    "            name = HumanName(tweet)\n",
    "            if name.full_name not in test[key]:\n",
    "                test[key][name.full_name] = 1\n",
    "            else:\n",
    "                test[key][name.full_name] += 1\n",
    "        else:\n",
    "            extracted_name = extract_from_tweet(tweet)\n",
    "            #print(extracted_name)\n",
    "            if len(extracted_name) != 0:\n",
    "                movies = ia.search_movie(''.join(extracted_name))\n",
    "                movies = [movie for movie in movies if 'year' in movie.keys() and movie['year'] <= 2013]\n",
    "                for i in range(len(movies)):\n",
    "                    if movies[i]['title'] not in test:\n",
    "                        test[key][movies[i]['title']] = 1\n",
    "                    else:\n",
    "                        test[key][movies[i]['title']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in test.items():\n",
    "    test[key] = nltk.FreqDist(value)\n",
    "    print(key, test[key].most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia = IMDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ia.search_person(\"supporting actress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = ia.search_movie(\"Zero Dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie[0][\"year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jessica Chastain Zero Dark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_results = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "for nltk_result in nltk_results:\n",
    "    if type(nltk_result) == Tree:\n",
    "        name = ''\n",
    "        for nltk_result_leaf in nltk_result.leaves():\n",
    "            name += nltk_result_leaf[0] + ' '\n",
    "            print(name)\n",
    "        print ('Type: ', nltk_result.label(), 'Name: ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
